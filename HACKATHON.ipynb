{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71069,"databundleVersionId":7802378,"sourceType":"competition"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook for SDD Hackathon 2024 wt Vortex.io ","metadata":{}},{"cell_type":"markdown","source":"## Library imports and dowloads","metadata":{}},{"cell_type":"code","source":"!git clone \"https://github.com/facebookresearch/segment-anything.git\"\n!pip install -q supervision --upgrade supervision","metadata":{"id":"ppg0EIg582UG","outputId":"7647c05f-60ff-4461-b218-7c28b6cd9525","execution":{"iopub.status.busy":"2024-02-27T10:28:22.322720Z","iopub.execute_input":"2024-02-27T10:28:22.323103Z","iopub.status.idle":"2024-02-27T10:28:37.672765Z","shell.execute_reply.started":"2024-02-27T10:28:22.323064Z","shell.execute_reply":"2024-02-27T10:28:37.671571Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Cloning into 'segment-anything'...\nremote: Enumerating objects: 295, done.\u001b[K\nremote: Total 295 (delta 0), reused 0 (delta 0), pack-reused 295\u001b[K\nReceiving objects: 100% (295/295), 18.30 MiB | 17.63 MiB/s, done.\nResolving deltas: 100% (155/155), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport supervision as sv\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pickle\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-02-27T10:17:57.023416Z","iopub.execute_input":"2024-02-27T10:17:57.023737Z","iopub.status.idle":"2024-02-27T10:18:04.653950Z","shell.execute_reply.started":"2024-02-27T10:17:57.023704Z","shell.execute_reply":"2024-02-27T10:18:04.653115Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## SAM initianlization","metadata":{}},{"cell_type":"code","source":"%cd segment-anything","metadata":{"id":"vetTn_yv86t4","outputId":"af9894a4-0e67-465a-b936-e59572b04595","execution":{"iopub.status.busy":"2024-02-27T10:18:04.655018Z","iopub.execute_input":"2024-02-27T10:18:04.655442Z","iopub.status.idle":"2024-02-27T10:18:04.661665Z","shell.execute_reply.started":"2024-02-27T10:18:04.655415Z","shell.execute_reply":"2024-02-27T10:18:04.660655Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/segment-anything\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth","metadata":{"id":"50yDODFy9EaV","execution":{"iopub.status.busy":"2024-02-27T10:18:04.664310Z","iopub.execute_input":"2024-02-27T10:18:04.664646Z","iopub.status.idle":"2024-02-27T10:18:17.345377Z","shell.execute_reply.started":"2024-02-27T10:18:04.664623Z","shell.execute_reply":"2024-02-27T10:18:17.343720Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nMODEL_TYPE = \"vit_h\"\n\n\nCHECKPOINT_PATH = \"./sam_vit_h_4b8939.pth\"\nsam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\nmask_generator = SamAutomaticMaskGenerator(sam)","metadata":{"id":"1mHRsRU09Ga1","execution":{"iopub.status.busy":"2024-02-27T10:18:17.348120Z","iopub.execute_input":"2024-02-27T10:18:17.348588Z","iopub.status.idle":"2024-02-27T10:18:26.358933Z","shell.execute_reply.started":"2024-02-27T10:18:17.348545Z","shell.execute_reply":"2024-02-27T10:18:26.357907Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### Fragmentation","metadata":{}},{"cell_type":"code","source":"def get_fragments(image_path):\n    image_bgr = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n    sam_result = mask_generator.generate(image_rgb)\n    masks = [o[\"segmentation\"] for o in sam_result]\n    all_mask = np.zeros(image_rgb.shape[:2])\n    for mask in masks:\n        all_mask = np.logical_or(all_mask, mask)\n    remaining = np.logical_not(all_mask)\n    fragments = [remaining.astype(int)]\n    fragments.extend([cv2.resize(mask.astype('float32'), (320, 240)).astype(int) for mask in masks])\n    return fragments","metadata":{"id":"qZ0OkeGVg9rG","execution":{"iopub.status.busy":"2024-02-27T10:18:26.360154Z","iopub.execute_input":"2024-02-27T10:18:26.360462Z","iopub.status.idle":"2024-02-27T10:18:26.367255Z","shell.execute_reply.started":"2024-02-27T10:18:26.360437Z","shell.execute_reply":"2024-02-27T10:18:26.366397Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_images_path = \"/kaggle/input/water-segmentation-vtx/dataset/trainset/images/\"\ntrain_masks_path = \"/kaggle/input/water-segmentation-vtx/dataset/trainset/masks/\"\ntest_images_path = \"/kaggle/input/water-segmentation-vtx/dataset/testset/images\"\nfiles = os.listdir(train_images_path)\nall_fragments = {}\n\nfor file in tqdm(files):\n    all_fragments[file] = get_fragments(train_images_path + file)","metadata":{"id":"zMnAk82ckw4N","outputId":"1b16879e-4626-402c-c265-78def1473f48","execution":{"iopub.status.busy":"2024-02-27T10:19:24.035994Z","iopub.execute_input":"2024-02-27T10:19:24.036385Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  8%|â–Š         | 71/891 [06:36<1:18:26,  5.74s/it]","output_type":"stream"}]},{"cell_type":"code","source":"# print(\"Saving fragments...\")\n# with open('training_fragments.pkl', 'wb') as f:\n#     pickle.dump(all_fragments, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fragment labelization","metadata":{}},{"cell_type":"code","source":"def get_label(frag, file, show=False):\n    mask_file = train_masks_path + file.replace(\n        \"jpg\", \"png\"\n    )\n    mask = cv2.imread(mask_file)\n    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)//255\n    test = mask * frag\n    if show:\n        plt.subplot(1,3,1)\n        img = cv2.imread(train_images_path + file)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n        plt.subplot(1,3,2)\n        plt.imshow(mask, vmin=0, vmax=1)\n        plt.subplot(1,3,3)\n        plt.imshow(frag, vmin=0, vmax=1)\n        plt.show()\n    return np.sum(test) / np.sum(frag) > .7\n\n\nfile = list(all_fragments.keys())[0]\nfrag = all_fragments[file][2]\nprint(get_label(frag, file, show=True))","metadata":{"id":"nSSOAiZTrvVd","outputId":"dea1eea7-adda-42b2-9fd2-40308589fa6d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fragment encoding","metadata":{}},{"cell_type":"code","source":"# Load a pretrained ResNet model\nmodel = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")\n# Remove the classification layer\nmodel = torch.nn.Sequential(*list(model.children())[:-1])\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define preprocessing transformations\npreprocess = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ndef get_features(frag):\n    input_tensor = preprocess(Image.fromarray(frag))\n    input_batch = input_tensor.unsqueeze(0)\n    with torch.no_grad():\n        features = model(input_batch)\n    return features.view(-1).numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fragment aggregation","metadata":{}},{"cell_type":"code","source":"def add_file_fragments(directory, file, fragments, training_set):\n    origin = cv2.imread(directory+file)\n    origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n    for frag in fragments:\n        resized_frag = cv2.resize(frag, origin.shape)\n        fragment = np.zeros(origin.shape)\n        for i in range(3):\n            fragment[:,:,i] = origin[:,:,i] * resized_frag.astype(int)\n        training_set.append(\n            {\n                \"filename\": file,\n                \"label\": get_label(resized_frag, file),\n                \"features\": get_features(fragment.astype(\"uint8\"))\n            }\n        )\n    \n\n# with open('training_fragments.pkl', 'rb') as f:\n#     all_fragments = pickle.load(f)\ntraining_set = []\nfor file in tqdm(all_fragments):\n    fragments = all_fragments[file]\n    add_file_fragments(train_images_path, file, fragments, training_set)\nprint(f\"{len(training_set)} fragments in training set.\")\nprint()\n# print(\"Saving fragments...\")\n# with open('training_set.pkl', 'wb') as f:\n#     pickle.dump(training_set, f)","metadata":{"id":"YW7JDQipoe8N","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"markdown","source":"### Fragmentation","metadata":{}},{"cell_type":"code","source":"test_fragments = {}\nprint(\"Fragmenting pictures...\")\nfor file in tqdm(files):\n    test_fragments[file] = get_fragments(test_images_path + file)\nprint(\"Done!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding","metadata":{}},{"cell_type":"code","source":"print(\"Getting fragment's features...\")\ntesting_set = []\nfor file in tqdm(test_fragments):\n    fragments = test_fragments[file]\n    origin = cv2.imread(directory+file)\n    origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n    for frag in fragments:\n        fragment = np.zeros(origin.shape)\n        for i in range(3):\n            fragment[:,:,i] = origin[:,:,i] * frag.astype(int)\n        testing_set.append(\n            {\n                \"filename\": file,\n                \"mask\": frag.astype(int),\n                \"features\": get_features(fragment.astype(\"uint8\"))\n            }\n        )\nprint(\"Done!\")\nprint()\n# print(\"Saving fragments...\")\n# with open('testing_set.pkl', 'wb') as f:\n#     pickle.dump(testing_set, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Labelization","metadata":{}},{"cell_type":"code","source":"def is_frag_water(frag, show=False):\n    scores = [cosine_similarity(frag[\"features\"].reshape(1,-1), \n                               o[\"features\"].reshape(1,-1)\n                              )[0][0] \n              for o in training_set]\n    best = np.argmax(scores)\n    if show:\n        plt.imshow(training_set[best][\"fragment\"])\n        plt.show()\n    return training_set[best][\"label\"]\n\n\nprint(\"Labeling test fragments...\")\n# with open('testing_set.pkl', 'rb') as f:\n#     testing_set = pickle.load(f)\nfor frag in testing_set:\n    frag[\"label\"] = is_frag_water(frag)\nprint(\"Done!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mask creation ","metadata":{}},{"cell_type":"code","source":"print(\"Merging water masks...\")\ntesting_masks = {}\nfor frag in testing_set:\n    file = frag[\"file\"]\n    if file in testing_masks:\n        mask = frag[\"mask\"]\n        testing_masks[file][\"mask\"] = testing_masks[file][\"mask\"] + cv2.resize(frag, testing_masks[file][\"shape\"])\n    else:\n        mask = {}\n        mask[\"shape\"] = cv2.imread(test_images_path+file).shape\n        mask[\"mask\"] = cv2.resize(frag, mask[\"shape\"])\n        testing_masks[file] = mask\nprint(\"Done!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission file generation","metadata":{}},{"cell_type":"code","source":"def boolean_array_to_rle(boolean_array):\n    boolean_vector = boolean_array.copy().reshape(1,-1)[0]\n    rle = []\n    current_idx = 0\n    current_value = -1\n    for i in range(len(boolean_vector)):\n        if boolean_vector[i] >= 1:\n            if current_value != 1:\n                current_value = 1\n                current_idx = i+1\n        else:\n            if current_value >= 1:\n                current_value = 0\n                rle.append((current_idx, i-current_idx+1))\n                current_idx = i+1\n    return rle\n\ndef rle_to_str(rle):\n    return \" \".join([f\"{e[0]} {e[1]}\" for e in rle])\n\nprint(\"Creating submission file...\")\nfiles = []\nrles = []\nfor file in testing_masks:\n    mask = testing_masks[file][\"mask\"]\n    name = file.replace(\"jpg\", \"png\")\n    rle = rle_to_str(boolean_array_to_rle(mask))\n    files.append(name)\n    rles.append(rle)\ndf = pd.DataFrame({'img_key': files, 'rle_mask': rles})\ndf.to_csv(\"SAM_submission.csv\", index=False)\nprint(\"Done!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}