{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71069,"databundleVersionId":7802378,"sourceType":"competition"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook for SDD Hackathon 2024 wt Vortex.io ","metadata":{}},{"cell_type":"markdown","source":"## Library imports and dowloads","metadata":{}},{"cell_type":"code","source":"!git clone \"https://github.com/facebookresearch/segment-anything.git\"\n!pip install -q supervision --upgrade supervision","metadata":{"id":"ppg0EIg582UG","outputId":"7647c05f-60ff-4461-b218-7c28b6cd9525","execution":{"iopub.status.busy":"2024-02-27T12:39:55.545658Z","iopub.execute_input":"2024-02-27T12:39:55.546003Z","iopub.status.idle":"2024-02-27T12:40:08.801929Z","shell.execute_reply.started":"2024-02-27T12:39:55.545974Z","shell.execute_reply":"2024-02-27T12:40:08.800895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport supervision as sv\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pickle\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-02-27T12:40:10.519650Z","iopub.execute_input":"2024-02-27T12:40:10.520305Z","iopub.status.idle":"2024-02-27T12:40:17.484543Z","shell.execute_reply.started":"2024-02-27T12:40:10.520271Z","shell.execute_reply":"2024-02-27T12:40:17.483617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SAM initianlization","metadata":{}},{"cell_type":"code","source":"%cd segment-anything","metadata":{"id":"vetTn_yv86t4","outputId":"af9894a4-0e67-465a-b936-e59572b04595","execution":{"iopub.status.busy":"2024-02-27T12:40:21.376776Z","iopub.execute_input":"2024-02-27T12:40:21.377292Z","iopub.status.idle":"2024-02-27T12:40:21.384791Z","shell.execute_reply.started":"2024-02-27T12:40:21.377246Z","shell.execute_reply":"2024-02-27T12:40:21.383874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth","metadata":{"id":"50yDODFy9EaV","execution":{"iopub.status.busy":"2024-02-27T10:18:04.664310Z","iopub.execute_input":"2024-02-27T10:18:04.664646Z","iopub.status.idle":"2024-02-27T10:18:17.345377Z","shell.execute_reply.started":"2024-02-27T10:18:04.664623Z","shell.execute_reply":"2024-02-27T10:18:17.343720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nMODEL_TYPE = \"vit_h\"\n\n\nCHECKPOINT_PATH = \"./sam_vit_h_4b8939.pth\"\nsam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\nmask_generator = SamAutomaticMaskGenerator(sam)","metadata":{"id":"1mHRsRU09Ga1","execution":{"iopub.status.busy":"2024-02-27T12:41:08.276347Z","iopub.execute_input":"2024-02-27T12:41:08.277234Z","iopub.status.idle":"2024-02-27T12:41:17.239076Z","shell.execute_reply.started":"2024-02-27T12:41:08.277192Z","shell.execute_reply":"2024-02-27T12:41:17.238035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### Fragmentation","metadata":{}},{"cell_type":"code","source":"def get_fragments(image_path):\n    image_bgr = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n    sam_result = mask_generator.generate(image_rgb)\n    masks = [o[\"segmentation\"] for o in sam_result]\n    all_mask = np.zeros(image_rgb.shape[:2])\n    for mask in masks:\n        all_mask = np.logical_or(all_mask, mask)\n    remaining = np.logical_not(all_mask)\n    fragments = [cv2.resize(remaining.astype('float32'), (320, 240)).astype(int)]\n    fragments.extend([cv2.resize(mask.astype('float32'), (320, 240)).astype(int) for mask in masks])\n    return fragments\n\ndef aggregate_fragment(fragments):\n    mask = np.zeros((240,320))\n    for i, frag in enumerate(fragments):\n        h, w = frag.shape\n        if h != 240 and w != 320:\n            frag = cv2.resize(frag.astype(\"float32\"), (320, 240)).astype(int)\n        if np.max(frag) > 1:\n            print(\"Max is not 1\")\n        mask = mask + frag * (i+1)\n    return mask.astype(\"uint8\")","metadata":{"id":"qZ0OkeGVg9rG","execution":{"iopub.status.busy":"2024-02-27T15:13:49.174990Z","iopub.execute_input":"2024-02-27T15:13:49.175362Z","iopub.status.idle":"2024-02-27T15:13:49.182975Z","shell.execute_reply.started":"2024-02-27T15:13:49.175334Z","shell.execute_reply":"2024-02-27T15:13:49.182065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images_path = \"/kaggle/input/water-segmentation-vtx/dataset/trainset/images/\"\ntrain_masks_path = \"/kaggle/input/water-segmentation-vtx/dataset/trainset/masks/\"\ntest_images_path = \"/kaggle/input/water-segmentation-vtx/dataset/testset/images/\"\nfiles = os.listdir(train_images_path)\nall_fragments = {}\ncluster_fragments = {}\n# num_choices = 100\nnum_choices = len(files)\n\ncount = 1\ncluster = 1\nfor file in tqdm(np.random.choice(files, size=num_choices)):\n    if count%150 == 0:\n        share_train_frags = {}\n        for file in cluster_fragments:\n            share_train_frags[file] = aggregate_fragment(cluster_fragments[file])\n        with open(f'../training_fragments_{cluster}.pkl', 'wb') as f:\n            pickle.dump(share_train_frags, f)\n        cluster += 1\n        all_fragments = {**all_fragments, **cluster_fragments}\n        cluster_fragments = {}\n    cluster_fragments[file] = get_fragments(train_images_path + file)\n    count+=1","metadata":{"id":"zMnAk82ckw4N","outputId":"1b16879e-4626-402c-c265-78def1473f48","execution":{"iopub.status.busy":"2024-02-27T15:34:17.424492Z","iopub.execute_input":"2024-02-27T15:34:17.425399Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 52%|█████▏    | 461/891 [43:04<39:52,  5.56s/it]  ","output_type":"stream"}]},{"cell_type":"markdown","source":"### Fragment labelization","metadata":{}},{"cell_type":"code","source":"def get_label(frag, file, show=False):\n    mask_file = train_masks_path + file.replace(\n        \"jpg\", \"png\"\n    )\n    mask = cv2.imread(mask_file)\n    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)//255\n    test = mask * frag\n    if show:\n        plt.subplot(1,3,1)\n        img = cv2.imread(train_images_path + file)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n        plt.subplot(1,3,2)\n        plt.imshow(mask, vmin=0, vmax=1)\n        plt.subplot(1,3,3)\n        plt.imshow(frag, vmin=0, vmax=1)\n        plt.show()\n    if np.sum(test) == np.sum(frag):\n        return True\n    return np.sum(test) / np.sum(frag) > .7\n","metadata":{"id":"nSSOAiZTrvVd","outputId":"dea1eea7-adda-42b2-9fd2-40308589fa6d","execution":{"iopub.status.busy":"2024-02-27T13:00:01.964266Z","iopub.execute_input":"2024-02-27T13:00:01.964929Z","iopub.status.idle":"2024-02-27T13:00:01.972354Z","shell.execute_reply.started":"2024-02-27T13:00:01.964894Z","shell.execute_reply":"2024-02-27T13:00:01.971441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fragment encoding","metadata":{}},{"cell_type":"code","source":"# Load a pretrained ResNet model\nmodel = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")\n# Remove the classification layer\nmodel = torch.nn.Sequential(*list(model.children())[:-1])\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define preprocessing transformations\npreprocess = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ndef get_features(frag):\n    input_tensor = preprocess(Image.fromarray(frag))\n    input_batch = input_tensor.unsqueeze(0)\n    with torch.no_grad():\n        features = model(input_batch)\n    return features.view(-1).numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T12:54:00.060805Z","iopub.execute_input":"2024-02-27T12:54:00.061169Z","iopub.status.idle":"2024-02-27T12:54:01.326584Z","shell.execute_reply.started":"2024-02-27T12:54:00.061139Z","shell.execute_reply":"2024-02-27T12:54:01.325591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fragment aggregation","metadata":{}},{"cell_type":"code","source":"def add_file_fragments(directory, file, fragments, training_set):\n    origin = cv2.imread(directory+file)\n    origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n    for frag in fragments:\n        h, w, _ = origin.shape\n        resized_frag = cv2.resize(frag.astype('float32') , (w,h))\n        fragment = np.zeros(origin.shape)\n        for i in range(3):\n            fragment[:,:,i] = origin[:,:,i] * resized_frag.astype(int)\n        training_set.append(\n            {\n                \"filename\": file,\n                \"label\": get_label(resized_frag, file),\n                \"features\": get_features(fragment.astype(\"uint8\"))\n            }\n        )\n    \n\n# with open('training_fragments.pkl', 'rb') as f:\n#     all_fragments = pickle.load(f)\ntraining_set = []\nfor file in tqdm(all_fragments):\n    fragments = all_fragments[file]\n    add_file_fragments(train_images_path, file, fragments, training_set)\nprint(f\"{len(training_set)} fragments in training set.\")\nprint()\n# print(\"Saving fragments...\")\n# with open('training_set.pkl', 'wb') as f:\n#     pickle.dump(training_set, f)","metadata":{"id":"YW7JDQipoe8N","execution":{"iopub.status.busy":"2024-02-27T13:00:07.360960Z","iopub.execute_input":"2024-02-27T13:00:07.361853Z","iopub.status.idle":"2024-02-27T13:04:38.237261Z","shell.execute_reply.started":"2024-02-27T13:00:07.361819Z","shell.execute_reply":"2024-02-27T13:04:38.236376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"markdown","source":"### Fragmentation","metadata":{}},{"cell_type":"code","source":"test_fragments = {}\nprint(\"Fragmenting pictures...\")\nfiles = os.listdir(test_images_path)\nfor file in tqdm(files):\n    test_fragments[file] = get_fragments(test_images_path + file)\nprint(\"Done!\")\nwith open(f'../testing_fragments.pkl', 'wb') as f:\n    pickle.dump(test_fragments, f)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:50:21.232844Z","iopub.execute_input":"2024-02-27T14:50:21.233217Z","iopub.status.idle":"2024-02-27T15:03:41.877110Z","shell.execute_reply.started":"2024-02-27T14:50:21.233188Z","shell.execute_reply":"2024-02-27T15:03:41.875988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding","metadata":{}},{"cell_type":"code","source":"print(\"Getting fragment's features...\")\ntesting_set = []\nfor file in tqdm(test_fragments):\n    fragments = test_fragments[file]\n    origin = cv2.imread(test_images_path+file)\n    origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n    h, w, _ = origin.shape\n    for frag in fragments:\n        fragment = np.zeros(origin.shape)\n        for i in range(3):\n            fragment[:,:,i] = origin[:,:,i] * cv2.resize(frag.astype(\"float32\"), (w, h)).astype(int)\n        testing_set.append(\n            {\n                \"filename\": file,\n                \"mask\": frag.astype(int),\n                \"features\": get_features(fragment.astype(\"uint8\"))\n            }\n        )\nprint(\"Done!\")\nprint()\n# print(\"Saving fragments...\")\n# with open('testing_set.pkl', 'wb') as f:\n#     pickle.dump(testing_set, f)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T13:23:09.502415Z","iopub.execute_input":"2024-02-27T13:23:09.503029Z","iopub.status.idle":"2024-02-27T13:33:32.133528Z","shell.execute_reply.started":"2024-02-27T13:23:09.502995Z","shell.execute_reply":"2024-02-27T13:33:32.132618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Labelization","metadata":{}},{"cell_type":"code","source":"def is_frag_water(frag, show=False):\n    scores = [cosine_similarity(frag[\"features\"].reshape(1,-1), \n                               o[\"features\"].reshape(1,-1)\n                              )[0][0] \n              for o in training_set]\n    best = np.argmax(scores)\n    if show:\n        plt.imshow(training_set[best][\"fragment\"])\n        plt.show()\n    return training_set[best][\"label\"]\n\n\nprint(\"Labeling test fragments...\")\n# with open('testing_set.pkl', 'rb') as f:\n#     testing_set = pickle.load(f)\ntest_features = [o['features'] for o in testing_set]\ntrain_features = [o['features'] for o in training_set]\nsimilarity = cosine_similarity(test_features, train_features)\nfor i, frag in tqdm(enumerate(testing_set)):\n    frag[\"label\"] = training_set[np.argmax(similarity[i])][\"label\"]\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:06:12.139162Z","iopub.execute_input":"2024-02-27T14:06:12.140070Z","iopub.status.idle":"2024-02-27T14:06:13.496197Z","shell.execute_reply.started":"2024-02-27T14:06:12.140021Z","shell.execute_reply":"2024-02-27T14:06:13.495174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mask creation ","metadata":{}},{"cell_type":"code","source":"print(\"Merging water masks...\")\ntesting_masks = {}\nfor frag in tqdm(testing_set):\n    file = frag[\"filename\"]\n    if frag[\"label\"]:\n        if file in testing_masks:\n            mask = frag[\"mask\"]\n            testing_masks[file][\"mask\"] = testing_masks[file][\"mask\"] + cv2.resize(mask.astype(\"float32\"), testing_masks[file][\"shape\"])\n        else:\n            mask = {}\n            h, w, _ = cv2.imread(test_images_path+file).shape\n            mask[\"shape\"] = (w, h)\n            mask[\"mask\"] = cv2.resize(frag[\"mask\"].astype(\"float32\"), mask[\"shape\"])\n            testing_masks[file] = mask\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:11:47.383415Z","iopub.execute_input":"2024-02-27T14:11:47.384299Z","iopub.status.idle":"2024-02-27T14:11:50.600823Z","shell.execute_reply.started":"2024-02-27T14:11:47.384262Z","shell.execute_reply":"2024-02-27T14:11:50.599942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission file generation","metadata":{}},{"cell_type":"code","source":"def boolean_array_to_rle(boolean_array):\n    boolean_vector = boolean_array.copy().reshape(1,-1)[0]\n    rle = []\n    current_idx = 0\n    current_value = -1\n    for i in range(len(boolean_vector)):\n        if boolean_vector[i] >= 1:\n            if current_value != 1:\n                current_value = 1\n                current_idx = i+1\n        else:\n            if current_value >= 1:\n                current_value = 0\n                rle.append((current_idx, i-current_idx+1))\n                current_idx = i+1\n    return rle\n\ndef rle_to_str(rle):\n    return \" \".join([f\"{e[0]} {e[1]}\" for e in rle])\n\nprint(\"Creating submission file...\")\nfiles = []\nrles = []\nfor file in tqdm(testing_masks):\n    mask = testing_masks[file][\"mask\"]\n    name = file.replace(\"jpg\", \"png\")\n    rle = rle_to_str(boolean_array_to_rle(mask))\n    files.append(name)\n    rles.append(rle)\ndf = pd.DataFrame({'img_key': files, 'rle_mask': rles})\ndf.to_csv(\"../submission.csv\", index=False)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:13:54.259602Z","iopub.execute_input":"2024-02-27T14:13:54.259985Z","iopub.status.idle":"2024-02-27T14:16:19.453702Z","shell.execute_reply.started":"2024-02-27T14:13:54.259955Z","shell.execute_reply":"2024-02-27T14:16:19.452770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualisation","metadata":{}},{"cell_type":"code","source":"visu_files = np.random.choice(files, 10)\nfor i, file in enumerate(visu_files):\n    plt.figure(figsize=(12,6))\n    plt.subplot(1,2,1)\n    origin = cv2.imread(test_images_path+file.replace(\"png\",\"jpg\"))\n    origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n    plt.imshow(origin)\n    plt.imshow(testing_masks[file.replace(\"png\",\"jpg\")]['mask'], alpha=.2, cmap='jet', vmax=1, vmin=0)\n    plt.subplot(1,2,2)\n    plt.imshow(testing_masks[file.replace(\"png\",\"jpg\")]['mask'], cmap='jet', vmin=0, vmax=1)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:26:02.133614Z","iopub.execute_input":"2024-02-27T14:26:02.134420Z","iopub.status.idle":"2024-02-27T14:26:06.643048Z","shell.execute_reply.started":"2024-02-27T14:26:02.134387Z","shell.execute_reply":"2024-02-27T14:26:06.642139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"share_test_set = {}\nfor file in tqdm(test_fragments):\n    fragments = test_fragments[file]\n    share_test_set[file] = aggregate_fragment(fragments)\n    \nprint(list(share_test_set.items())[0])\n\nimport sys\nsys.getsizeof(share_test_set)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T15:25:39.675605Z","iopub.execute_input":"2024-02-27T15:25:39.675951Z","iopub.status.idle":"2024-02-27T15:25:41.427090Z","shell.execute_reply.started":"2024-02-27T15:25:39.675926Z","shell.execute_reply":"2024-02-27T15:25:41.426177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../share_test_set.pkl', 'wb') as f:\n    pickle.dump(share_test_set, f)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T15:25:48.449930Z","iopub.execute_input":"2024-02-27T15:25:48.450775Z","iopub.status.idle":"2024-02-27T15:25:48.503319Z","shell.execute_reply.started":"2024-02-27T15:25:48.450729Z","shell.execute_reply":"2024-02-27T15:25:48.502339Z"},"trusted":true},"execution_count":null,"outputs":[]}]}